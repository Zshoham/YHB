{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_workshop_assignment1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zshoham/YHB/blob/main/deep_learning_workshop_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHHsmjovnMFS"
      },
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIpx2rL8xE2g"
      },
      "source": [
        "def reshape_data(data):\n",
        "  images = list()\n",
        "  for d in data:\n",
        "      image = np.zeros((32,32,3), dtype=np.uint8)\n",
        "      image[...,0] = np.reshape(d[:1024], (32,32)) # Red channel\n",
        "      image[...,1] = np.reshape(d[1024:2048], (32,32)) # Green channel\n",
        "      image[...,2] = np.reshape(d[2048:], (32,32)) # Blue channel\n",
        "      images.append(image)\n",
        "  return np.array(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk9BqS8iJNF7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "\n",
        "data = requests.get(\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\")\n",
        "with open(\"cifar100\", 'wb') as f:\n",
        "    f.write(data.content) \n",
        "\n",
        "tar = tarfile.open(\"cifar100\", \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "cifar_train = unpickle(\"cifar-100-python/train\")\n",
        "cifar_test = unpickle(\"cifar-100-python/test\")\n",
        "\n",
        "train_data = reshape_data(cifar_train[b'data'])\n",
        "train_labels = cifar_train[b'coarse_labels']\n",
        "train_fine_labels = cifar_train[b'fine_labels']\n",
        "\n",
        "\n",
        "test_data = reshape_data(cifar_test[b'data'])\n",
        "test_labels = cifar_test[b'coarse_labels']\n",
        "test_fine_labels = cifar_test[b'fine_labels']\n",
        "\n",
        "meta = unpickle(\"cifar-100-python/meta\")\n",
        "label_names = meta[b'coarse_label_names']\n",
        "fine_label_names = meta[b'fine_label_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVVtbX_0arLt"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3eWa75oKklK"
      },
      "source": [
        "print(\"number of high level labels: \" + str(len(label_names)))\n",
        "print(\"number of low level labels: \" + str(len(fine_label_names)))\n",
        "\n",
        "print(\"number of training imeges: \" + str(len(train_data)))\n",
        "print(\"number of testing imeges: \" + str(len(test_data)))\n",
        "\n",
        "train_lbl, train_lbl_counts = np.unique(train_labels, return_counts=True)\n",
        "train_fine_lbl, train_fine_lbl_counts = np.unique(train_fine_labels, return_counts=True)\n",
        "\n",
        "test_lbl, test_lbl_counts = np.unique(test_labels, return_counts=True)\n",
        "test_fine_lbl, test_fine_lbl_counts = np.unique(test_fine_labels, return_counts=True)\n",
        "\n",
        "fig, aux = plt.subplots(4, figsize=(40,20))\n",
        "aux[0].bar(train_lbl, train_lbl_counts, label=\"training high level label distribution\")\n",
        "aux[1].bar(train_fine_lbl, train_fine_lbl_counts, label=\"training low level label distribution\")\n",
        "aux[2].bar(test_lbl, test_lbl_counts, label=\"testing high level label distribution\")\n",
        "aux[3].bar(test_fine_lbl, test_fine_lbl_counts, label=\"testing low level label distribution\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeJPIttG9alt"
      },
      "source": [
        " As we can see from the plots above, the label distribution in the data is perfectly uniform, each high level label having 2500 training examples and 500 testing examples, while each low level label has 500 training examples and 100 testing examples."
      ]
    }
  ]
}